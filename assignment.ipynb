{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "919d67f9-5a30-4eb8-be92-8e67482cdc3f",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Data Acquisition and Processing Systems (DaPS) (ELEC0136)    \n",
    "### Final Assignment\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc5b0021-1259-41ab-bdbb-c076828cd77f",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-info\">\n",
    "\n",
    "#### Task 1: Data Acquisition\n",
    "\n",
    "You will first have to acquire the necessary data for conducting your study. One essential type of\n",
    "data that you will need, are the stock prices for each company from April 2017 to April 202 1 as\n",
    "described in Section 1. Since these companies are public, the data is made available online. The\n",
    "first task is for you to search and collect this data, finding the best way to access and download\n",
    "it. A good place to look is on platforms that provide free data relating to the stock market such as\n",
    "Google Finance or Yahoo! Finance.\n",
    "\n",
    "[Optional] Providing more than one method to acquire the very same or different data, e.g. from\n",
    "a downloaded comma-separated-value file and a web API, will result in a higher score.\n",
    "\n",
    "There are many valuable sources of information for analysing the stock market. In addition to time\n",
    "series depicting the evolution of stock prices, acquire auxiliary data that is likely to be useful for\n",
    "the forecast, such as:\n",
    "\n",
    "- Social Media, e.g., Twitter: This can be used to uncover the public’s sentimental\n",
    "response to the stock market\n",
    "- Financial reports: This can help explain what kind of factors are likely to affect the stock\n",
    "market the most\n",
    "- News: This can be used to draw links between current affairs and the stock market\n",
    "- Climate data: Sometimes weather data is directly correlated to some companies’ stock\n",
    "prices and should therefore be taken into account in financial analysis\n",
    "- Others: anything that can justifiably support your analysis.\n",
    "\n",
    "Remember, you are looking for historical data, not live data.\n",
    "   \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c614bfb6-cdf2-414c-9dee-ea8a8db97de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def acquire():\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81cd303d-9419-4993-a2b3-fe143bf2d954",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "26ea523a-6d00-46db-873b-476600070902",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-info\">\n",
    "    \n",
    "## Task 2: Data Storage\n",
    "\n",
    "Once you have found a way to acquire the relevant data, you need to decide on how to store it.\n",
    "You should choose a format that allows an efficient read access to allow training a parametric\n",
    "model. Also, the data corpus should be such that it can be easily inspected. Data can be stored\n",
    "locally, on your computer.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "224e0f8c-da42-4b91-a696-3c1f5d52ce89",
   "metadata": {},
   "outputs": [],
   "source": [
    "def store(data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f354e27-4e73-49db-871d-8f7319376fe6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "0746eb74-c388-4722-a0b8-b7a81f4a4182",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-warning\">\n",
    "\n",
    "[Optional] Create a simple API to allow Al retrieving the compound of data you collected. It is enough to provide a single access point to retrieve all the data, and not implement query mechanism. The API must be accessible from the web. If you engage in this task data must be stored online.  \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3882fe99-4d00-4367-8a1c-48592c16d091",
   "metadata": {},
   "outputs": [],
   "source": [
    "def retrieve(data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.    \n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a4f775e-173b-4a16-b46e-0a8265a0eaba",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "bc93fdd1-7c24-403c-b36f-66906d29ebaa",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-info\">\n",
    "\n",
    "## Task 3: Data Preprocessing\n",
    "\n",
    "Now that you have the data stored, you can start preprocessing it. Think about what features to\n",
    "keep, which ones to transform, combine or discard. Make sure your data is clean and consistent\n",
    "(e.g., are there many outliers? any missing values?). You are expected to:\n",
    "\n",
    "1. Clean the data from missing values and outliers, if any.\n",
    "2. Provide useful visualisation of the data. Plots should be saved on disk, and not printed on\n",
    "the juptyer notebook.\n",
    "3. Transform your data (e.g., using normalization, dimensionality reduction, etc.) to improve\n",
    "the forecasting performance.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c5458b2-98ca-4301-8a58-7309b6e72cb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def process(data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e6fc43-5ac4-429d-9f42-ee77cc8d56a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "166a02fb-ad30-4ac8-b45a-16ba63299839",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-info\">\n",
    "    \n",
    "## Task 4: Data Exploration\n",
    "\n",
    "After ensuring that the data is well preprocessed, it is time to start exploring the data to carry out\n",
    "hypotheses and intuition about possible patterns that might be inferred. Depending on the data,\n",
    "different EDA (exploratory data analysis) techniques can be applied, and a large amount of\n",
    "information can be extracted.\n",
    "For example, you could do the following analysis:\n",
    "\n",
    "    \n",
    "- Time series data is normally a combination of several components:\n",
    "  - Trend represents the overall tendency of the data to increase or decrease over time.\n",
    "  - Seasonality is related to the presence of recurrent patterns that appear after regular\n",
    "intervals (like seasons).\n",
    "  - Random noise is often hard to explain and represents all those changes in the data\n",
    "that seem unexpected. Sometimes sudden changes are related to fixed or predictable\n",
    "events (i.e., public holidays).\n",
    "- Features correlation provides additional insight into the data structure. Scatter plots and\n",
    "boxplots are useful tools to spot relevant information.\n",
    "- Explain unusual behaviour.\n",
    "- Explore the correlation between stock price data and other external data that you can\n",
    "collect (as listed in Sec 2.1)\n",
    "- Use hypothesis testing to better understand the composition of your dataset and its\n",
    "representativeness.\n",
    "\n",
    "    \n",
    "At the end of this step, provide key insights on the data. This data exploration procedure should\n",
    "inform the subsequent data analysis/inference procedure, allowing one to establish a predictive\n",
    "relationship between variables.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "191b9ba6-7e5f-47dd-ba43-902b0972e2e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "def explore(data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5374f0c7-95dd-4978-9612-2c45396b0dfc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3de2cc9-5f92-48b5-aa99-2c12dbf74990",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-info\">\n",
    "\n",
    "## Task 5: Inference\n",
    "\n",
    "Train a model to predict the closing stock price on each day for the data you have already\n",
    "collected, stored, preprocessed and explored from previous steps. The data must be spanning\n",
    "from April 2017 to April 202 1.\n",
    "You should develop two separate models:\n",
    "\n",
    "\n",
    "1. A model for predicting the closing stock price on each day for a 1-month time window (until\n",
    "    end of May 202 1 ), using only time series of stock prices.\n",
    "2. A model for predicting the closing stock price on each day for a 1-month time window (until\n",
    "    end of May 202 1 ), using the time series of stock prices and the auxiliary data you collected.\n",
    "Which model is performing better? How do you measure performance and why? How could you\n",
    "further improve the performance? Are the models capable of predicting the closing stock prices\n",
    "far into the future?\n",
    "\n",
    "[IMPORTANT NOTE] For these tasks, you are not expected to compare model architectures, but\n",
    "examine and analyse the differences when training the same model with multiple data attributes\n",
    "and information from sources. Therefore, you should decide a single model suitable for time series\n",
    "data to solve the tasks described above. Please see the lecture slides for tips on model selection\n",
    "and feel free to experiment before selecting one.\n",
    "\n",
    "The following would help you evaluate your approach and highlight potential weaknesses in your\n",
    "process:\n",
    "\n",
    "1. Evaluate the performance of your model using different metrics, e.g. mean squared error,\n",
    "    mean absolute error or R-squared.\n",
    "2. Use ARIMA and Facebook Prophet to explore the uncertainty on your model’s predicted\n",
    "    values by employing confidence bands.\n",
    "3. Result visualization: create joint plots showing marginal distributions to understand the\n",
    "    correlation between actual and predicted values.\n",
    "4. Finding the mean, median and skewness of the residual distribution might provide\n",
    "    additional insight into the predictive capability of the model.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d85b117-1d3e-46a0-ab2b-a031b0d05b55",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, train_data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60c3918-fc22-4609-a3f8-3d39deffae90",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e30e9e7-b431-4e7b-9d2d-e5495e3ef8d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(trained_model, val_data):\n",
    "    # Implement me, and remove the exception below.\n",
    "    # Make sure you return what you need.\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1eabd1f2-e948-4c4f-8c7d-b175a886c953",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3b389aa-b4b3-47a1-8893-e24d38a60f9d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-heading alert-danger\">\n",
    "\n",
    "## Autorun\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bfab70d1-6422-4441-a038-2a963f7158ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def main():\n",
    "    \"\"\"This function will be called to check that your work is reproducible, and it is the only function that will be called by us.\n",
    "    It should perform all the work that you used to support your Report, e.g. storing data, running experiments, saving figures.\n",
    "    \n",
    "    Example:\n",
    "    ```\n",
    "    data = acquire()\n",
    "    store(data)\n",
    "    data = process(data)\n",
    "    explore(data)\n",
    "    model = create_model()\n",
    "    trained_model = train(model, data)\n",
    "    performance = evaluate(trained_model, data)\n",
    "    ```\n",
    "    \"\"\"\n",
    "    raise NotImplementedError()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2216cb62-0db6-4d91-bee3-5af833952b90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
